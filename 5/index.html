<!DOCTYPE html>
<html lang="en">
  <head>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CS180 project 4</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
      }
      header {
        background-color: #333;
        color: white;
        padding: 10px 20px;
        text-align: center;
      }
      .container {
        max-width: 1000px;
        margin: 20px auto;
        padding: 20px;
        background-color: white;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
      }
      h2 {
        color: #333;
      }
      p {
        line-height: 1.6;
      }
      .image-section {
        display: flex;
        justify-content: center;
        flex-wrap: wrap;
        gap: 20px;
        margin-top: 20px;
        width: 100%;
        height: auto;
      }
      .image-card {
        flex: 1;
        min-width: 100px;
        max-width: 1000px;
        text-align: center;
      }
      .image-card img {
        width: 100%;
        max-width: 500px;
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
      }
      .image-card p {
        margin-top: 10px;
      }
      .row-images {
        display: flex;
        flex-direction: row;
        justify-content: space-between;
        gap: 10px;
        flex-wrap: nowrap;
        width: 100%;
        overflow-x: auto;
      }

      .row-images .image-card {
        flex: 1;
        text-align: center;
      }

      .row-images .image-card img {
        width: 100px; /* Set smaller width only for these specific images */
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
      }
      .flipped-image {
            transform: rotate(180deg);
        }

        /* Optional: style adjustments */
        .image-section {
            display: flex;
            gap: 20px;
        }
        .image-card {
            text-align: center;
        }
      .two-column {
        display: flex;
        flex-wrap: wrap; /* Ensures responsiveness */
        gap: 20px; /* Adds some space between the columns */
        margin-top: 20px;
      }

      .text-column {
        flex: 1;
        min-width: 200px;
      }

      .image-column {
        flex: 1;
        min-width: 200px;
        text-align: center;
      }

      .image-column img {
        max-width: 100%;
        height: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
      }

      .equation {
        font-family: "Courier New", Courier, monospace;
        background-color: #f4f4f4;
        padding: 10px;
        display: inline-block;
      }
      h1,
      h2 {
        color: #333;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>CS180 project 5</h1>
    </header>
    <div class="container">
      <section>
        <h2>The Power of Diffusion Models! (Part A)</h2>
        <p>
          In this project I implement diffusion loops and leverage them for various image generation tasks like inpainting and creating visual anagrams or hybrid images.
        </p>
      </section>
      <section>
        <h2>Part 0: A few examples with DeepFloyd</h2>
        <p>
            <a href="https://huggingface.co/DeepFloyd/IF-I-XL-v1.0"> "DeepFloyd"</a> 
            is a two stage Diffusion model trained by Stability AI. The first stage generates 64 x 64 images and then upsamples them 256 x 256. 
            Below are some outputs with varrying numbers of iteratives steps which dictate how many denoising steps are taken. 
            As supported by the images, as you take more steps you get clearer more detailed imagse but the runtime increases quite a bit, consequently.
        </p>
      </section>
      <section class="image-section">
        <div class="image-card">
          <img src="media/prompt1_i10_256by.png" alt="" />
          <p>"an oil painting of a snowy mountain village" 10 iteratitions 256x256</p>
        </div>
        <div class="image-card">
          <img src="media/prompt2_i10_256by.png" alt="" />
          <p>"a man wearing a hat" 10 iterations 256x256</p>
        </div>
        <div class="image-card">
            <img src="media/prompt3_i10_256by.png" alt="" />
            <p>"a rocket ship" 10 iterations 256x256</p>
          </div>
      </section>
      <section class="image-section">
        <div class="image-card">
          <img src="media/prompt1_i20_256by.png" alt="" />
          <p>"an oil painting of a snowy mountain village" 20 iteratitions 256x256</p>
        </div>
        <div class="image-card">
          <img src="media/prompt2_i20_256by.png" alt="" />
          <p>"a man wearing a hat" 20 iterations 256x256</p>
        </div>
        <div class="image-card">
            <img src="media/prompt3_i20_256by.png" alt="" />
            <p>"a rocket ship" 20 iterations 256x256</p>
          </div>
      </section>
      <section class="image-section">
        <div class="image-card">
          <img src="media/prompt1_i500_256by.png" alt="" />
          <p>"an oil painting of a snowy mountain village" 500 iteratitions 256x256</p>
        </div>
        <div class="image-card">
          <img src="media/prompt2_i500_256by.png" alt="" />
          <p>"a man wearing a hat" 500 iterations 256x256</p>
        </div>
        <div class="image-card">
            <img src="media/prompt3_i500_256by.png" alt="" />
            <p>"a rocket ship" 500 iterations 256x256</p>
          </div>
      </section>
      <section>
        <h2>Part 1.1 Forward Pass of sampling loop. </h2>
        <p>
          The idea of a sampling loop is to begin with a clean image x<sub>0</sub> and 
          progressively add more noise to this image giving x<sub>t</sub> until 
          at timestep <em>t=T</em> we have in image of essentially pure noise. 
          The goal of a diffusion model is to remove this noise by predicting the noise in an image.
        </p>

        <p>
            The first step is the forward pass, which encompasses adding noise to a clean image. This process is defined by the formula:
            <br />
            x<sub>t</sub> = √<span style="text-decoration: overline;">&alpha;<sub>t</sub></span> x<sub>0</sub> + √<span style="text-decoration: overline;">1 - &alpha;<sub>t</sub></span> &epsilon;
            <br />
            where <span style="text-decoration: overline;">&alpha;<sub>t</sub></span> is the noise coefficient. Below are noisy images at various <em>t</em> values for a sample image of the campanile.
          </p>

        <section class="image-section">
            <div class="image-card">
              <img src="media/berkeley_campanile.jpg" alt="" />
              <p>Berkeley Campanile</p>
            </div>
            <div class="image-card">
              <img src="media/test_image_at_t250.jpg" alt="" />
              <p>Campanile at t = 250</p>
            </div>
            <div class="image-card">
                <img src="media/test_image_at_t500.jpg" alt="" />
                <p>Campanile at t = 500</p>
            </div>
            <div class="image-card">
                <img src="media/test_image_at_t750.jpg" alt="" />
                <p>Campanile at t = 750</p>
            </div>
          </section>
        <section>
          <h2>Part 1.2 Classical Denoising</h2>
          <p>
            A basic approach to denoising is to use a Gaussian blurr to remove the noise in the image, however as seen below the results are not so great.
          </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/test_image_at_t250.jpg" alt="" />
              <p>Campanile at t = 250</p>
            </div>
            <div class="image-card">
              <img src="media/test_image_at_t500.jpg" alt="" />
              <p>Campanile at t = 500 </p>
            </div>
            <div class="image-card">
                <img src="media/test_image_at_t750.jpg" alt="" />
                <p>Campanile at t = 750</p>
              </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/denoised_image_at_t250.jpg" alt="" />
              <p>Campanile at t = 250 Denoised</p>
            </div>
            <div class="image-card">
              <img src="media/denoised_image_at_t500.jpg" alt="" />
              <p>Campanile at t = 500 Denoised</p>
            </div>
            <div class="image-card">
                <img src="media/denoised_image_at_t750.jpg" alt="" />
                <p>Campanile at t = 750 Denoised</p>
              </div>
        </section>
        <section>
          <h2>Part 1.3 One-Step Denoising</h2>
          <p>
            For this part we use a pretrained UNet to recover gaussian noise dorm the image and then remove this noise and in theory getr something close to the original image. I ran this for <em>t</em> = [250, 500, 750] and displayed the images below.
          </p>
          <section class="image-section">
            <div class="image-card">
              <img src="media/noisy_campanile_at_t250.jpg" alt="" />
              <p>Noisy Campanile at t=250</p>
            </div>
            <div class="image-card">
              <img src="media/noisy_campanile_at_t500.jpg" alt="" />
              <p>Noisy Campanile at t=500</p>
            </div>
            <div class="image-card">
                <img src="media/noisy_campanile_at_t750.jpg" alt="" />
                <p>Noisy Campanile at t=750</p>
              </div>
          </section>
          <section class="image-section">
            <div class="image-card">
              <img src="media/one_Step_denoised_campanile_at_t250.jpg" alt="" />
              <p>One-Step Denoised Campanile at t=250</p>
            </div>
            <div class="image-card">
              <img src="media/one_Step_denoised_campanile_at_t500.jpg" alt="" />
              <p>One-Step Denoised Campanile at t=500</p>
            </div>
            <div class="image-card">
                <img src="media/one_Step_denoised_campanile_at_t750.jpg" alt="" />
                <p>One-Step Denoised Campanile at t=750</p>
              </div>
          </section>
        </section>
        <section>
          <h2>Part 1.4 Iterative Denoising</h2>
          <p>
            In the last part we can see that the UNet struggles as you add more noise. 
            For this part we iteratively denoise meaning that we denoise from x<sub>1000</sub> to x<sub>0</sub> step by step, we do so in strides of 30 to speed this up.
            The formula for computing the next step is:
          </p>
          <p>
            \( x_{t'} = \frac{\sqrt{\overline{\alpha_{t'}} \beta_t}}{1 - \overline{\alpha_t}} x_0 + 
            \sqrt{\alpha_t \frac{(1 - \overline{\alpha_{t'}})}{1 - \overline{\alpha_t}}} x_t + v \sigma \)
        </p>
        <p>
            Where <i>&alpha;</i><sub>t</sub> = <i>&alpha;</i><sub>t</sub> &#x2215; <i>&alpha;</i><sub>t'</sub>
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/iterative_denoise_90.jpg" alt="" />
            <p>Noisy Campanile at t=90</p>
          </div>
          <div class="image-card">
            <img src="media/iterative_denoise_240.jpg" alt="" />
            <p>Noisy Campanile at t=240</p>
          </div>
          <div class="image-card">
            <img src="media/iterative_denoise_390.jpg" alt="" />
            <p>Noisy Campanile at t=390</p>
          </div>
          <div class="image-card">
            <img src="media/iterative_denoise_540.jpg" alt="" />
            <p>Noisy Campanile at t=540</p>
          </div>
          <div class="image-card">
            <img src="media/iterative_denoise_690.jpg" alt="" />
            <p>Noisy Campanile at t=690</p>
          </div>
        </section>
        <section class="image-section">
            <div class="image-card">
                <img src="media/berkeley_campanile.jpg" alt="" />
                <p>Originial Campanile</p>
              </div>
          <div class="image-card">
            <img src="media/iterative_denoise.jpg" alt="" />
            <p>Iteratively Denoised Campanile</p>
          </div>
          <div class="image-card">
            <img src="media/onestep_denoise.jpg" alt="" />
            <p>One-step Denoised Campanile</p>
          </div>
          <div class="image-card">
            <img src="media/gaussian_blurred.jpg" alt="" />
            <p>Gaussian Blurred Campanile</p>
          </div>
        </section>
    </section>
    <section>
        <h2>Part 1.5 Diffusion Model Sampling</h2>
        <p>
          We can use our iterative denoising to generate images form scratch, passing random noise in and making the text prompt "a high quality photo". Here's 5 results of that below. 
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/generated_image_0.jpg" alt="" />
            <p>Sample 1</p>
          </div>
          <div class="image-card">
            <img src="media/generated_image_1.jpg" alt="" />
            <p>Sample 2</p>
          </div>
          <div class="image-card">
            <img src="media/generated_image_2.jpg" alt="" />
            <p>Sample 3</p>
          </div>
          <div class="image-card">
            <img src="media/generated_image_3.jpg" alt="" />
            <p>Sample 4</p>
          </div>
          <div class="image-card">
            <img src="media/generated_image_4.jpg" alt="" />
            <p>Sample 5</p>
          </div>
        </section>
      </section>
      <section>
        <h2>Part 1.6 Classifier-Free Guidance (CFG)</h2>
        <p>
          The images from the previous section lack in quality and sometimes even appear nonsensical. 
          To improve the results we'll use classifier-free guidance to refine the images by computing two different noise estimates: a <em>conditional noise estimate</em> and an <em>unconditional noise estimate</em>. 
          By combining these two estimates, we can control the balance between diversity and quality in the images we generate.
        </p>
        <div class="formula-section">
            <p>
                In CFG, we denote the conditional noise estimate as \( \epsilon_{\text{cond}} \) and the unconditional noise estimate as \( \epsilon_{\text{uncond}} \).
                Our new noise estimate \( \epsilon \) is then given by:
            </p>
            <p style="text-align: center;">
                \[
                \epsilon = \epsilon_{\text{uncond}} + s \cdot (\epsilon_{\text{cond}} - \epsilon_{\text{uncond}})
                \]
            </p>
            <p>
                Here, \( s \) is a scaling factor that controls the strength of the guidance. By adjusting \( s \), we can achieve different effects:
            </p>
            <ul>
                <li>When \( s = 0 \), we obtain a purely unconditional noise estimate.</li>
                <li>When \( s = 1 \), we recover the conditional noise estimate.</li>
                <li>For values \( s > 1 \), we achieve enhanced image quality, often at the expense of diversity.</li>
            </ul>
            <p>
                The true "magic" of CFG happens when \( s > 1 \). In this case, the generated images are often much higher in quality, providing clearer and more meaningful visuals compared to the unguided generation process.
            </p>
        </div>
        <section class="image-section">
          <div class="image-card">
            <img src="media/cfg_generated_image_0.jpg" alt="" />
            <p>Sample 1 with CFG</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_image_1.jpg" alt="" />
            <p>Sample 2 with CFG</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_image_2.jpg" alt="" />
            <p>Sample 3 with CFG</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_image_3.jpg" alt="" />
            <p>Sample 4 with CFG</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_image_4.jpg" alt="" />
            <p>Sample 5 with CFG</p>
          </div>
        </section>
      </section>
      <section>
        <h2>Part 1.7 Image-to-image Translation</h2>
        <p>
          We can take what we did in 1.4 and by adding more noise we force our algorithm to make a larger edit in hopes that it will be "creative" i.e. hallucinate a bit and produce something cool. This can be thought of as forcing a noisy image back onto the manifold of natural images. I tried this with varrying values for the starting index, and you can see that as the edits go on the image looks more like the original.
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/campanile_noise_level_1.png" alt="" />
            <p>i_start = 1</p>
          </div>
          <div class="image-card">
            <img src="media/campanile_noise_level_3.png" alt="" />
            <p>i_start = 3</p>
          </div>
          <div class="image-card">
            <img src="media/campanile_noise_level_5.png" alt="" />
            <p>i_start = 5</p>
          </div>
          <div class="image-card">
            <img src="media/campanile_noise_level_7.png" alt="" />
            <p>i_start = 7</p>
          </div>
          <div class="image-card">
            <img src="media/campanile_noise_level_10.png" alt="" />
            <p>i_start = 10</p>
          </div>
          <div class="image-card">
            <img src="media/campanile_noise_level_20.png" alt="" />
            <p>i_start = 20</p>
          </div>
        </section>
      </section>
      <section>
        <h2>Part 1.7.1 Editing Hand-Drawn and Web Images</h2>
        <p>
          The procedure above works even better if you start with a nonrealistic image like a drawing or painting and project it onto the manifold of natural images. I've done this with some images from the web as well as a few hand drawn scribbles.
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/web_im_noise_level_1.png" alt="" />
            <p>Avocado i_start = 1</p>
          </div>
          <div class="image-card">
            <img src="media/web_im_noise_level_10.png" alt="" />
            <p>Avocado i_start = 3</p>
          </div>
          <div class="image-card"> 
            <img src="media/web_im_noise_level_5.png" alt="" />
            <p>Avocado i_start = 5</p>
          </div>
          <div class="image-card">
            <img src="media/web_im_noise_level_7.png" alt="" />
            <p>Avocado i_start = 7</p>
          </div>
          <div class="image-card">
            <img src="media/web_im_noise_level_10.png" alt="" />
            <p>Avocado i_start = 10</p>
          </div>
          <div class="image-card">
            <img src="media/web_im_noise_level_20.png" alt="" />
            <p>Avocado i_start = 20</p>
          </div>
          <div class="image-card">
            <img src="media/avocado_original.jpg" alt="" />
            <p>Avocado original</p>
          </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/drawn1_noise_level1.png" alt="" />
              <p>Apple scribble i_start = 1</p>
            </div>
            <div class="image-card">
              <img src="media/drawn1_noise_level3.png" alt="" />
              <p>Apple scribble i_start = 3</p>
            </div>
            <div class="image-card"> 
              <img src="media/drawn1_noise_level5.png" alt="" />
              <p>Apple scribble i_start = 5</p>
            </div>
            <div class="image-card">
              <img src="media/drawn1_noise_level7.png" alt="" />
              <p>Apple scribble i_start = 7</p>
            </div>
            <div class="image-card">
              <img src="media/drawn1_noise_level10.png" alt="" />
              <p>Apple scribble i_start = 10</p>
            </div>
            <div class="image-card">
              <img src="media/drawn1_noise_level20.png" alt="" />
              <p>Apple scribble i_start = 20</p>
            </div>
            <div class="image-card">
              <img src="media/drawn1_original.png" alt="" />
              <p>Apple scribble original</p>
            </div>
          </section>
          <section class="image-section">
            <div class="image-card">
              <img src="media/drawn2_noise_level1.png" alt="" />
              <p>Man scribble i_start = 1</p>
            </div>
            <div class="image-card">
              <img src="media/drawn2_noise_level3.png" alt="" />
              <p>Man scribble i_start = 3</p>
            </div>
            <div class="image-card"> 
              <img src="media/drawn2_noise_level5.png" alt="" />
              <p>Man scribble i_start = 5</p>
            </div>
            <div class="image-card">
              <img src="media/drawn2_noise_level7.png" alt="" />
              <p>Man scribble i_start = 7</p>
            </div>
            <div class="image-card">
              <img src="media/drawn2_noise_level10.png" alt="" />
              <p>Man scribble i_start = 10</p>
            </div>
            <div class="image-card">
              <img src="media/drawn2_noise_level20.png" alt="" />
              <p>Man scribble i_start = 20</p>
            </div>
            <div class="image-card">
              <img src="media/drawn2_original.png" alt="" />
              <p>Man original</p>
            </div>
          </section>
      </section>
      <section>
        <h2>Part 1.7.2 Inpainting</h2>
        <p>
          We can use a mask to create an image that has the original content of the image in some parts, but generated content in other parts. For this I put a mask over the upper portion of the campanile and generated a few results.
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/inpainted_image_0 (1).png" alt="" />
            <p>Sample 1</p>
          </div>
          <div class="image-card">
            <img src="media/inpainted_image_1 (1).png" alt="" />
            <p>Sample 2</p>
          </div>
          <div class="image-card">
            <img src="media/inpainted_image_2 (1).png" alt="" />
            <p>Sample 3</p>
          </div>
          <div class="image-card">
            <img src="media/inpainted_image_3 (1).png" alt="" />
            <p>Sample 4</p>
          </div>
          <div class="image-card">
            <img src="media/inpainted_image_4 (1).png" alt="" />
            <p>Sample 5</p>
          </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/inpainted_david_0.png" alt="" />
              <p>Sample 1</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_david_1.png" alt="" />
              <p>Sample 2</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_david_2.png" alt="" />
              <p>Sample 3</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_david_3.png" alt="" />
              <p>Sample 4</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_david_4.png" alt="" />
              <p>Sample 5</p>
            </div>
            <div class="image-card">
                <img src="media/statue_david.jpg" alt="" />
                <p>Original</p>
              </div>
            <div class="image-card">
            <img src="media/mask_david.jpg" alt="" />
            <p>Mask</p>
            </div>
          </section>
          <section class="image-section">
            <div class="image-card">
              <img src="media/inpainted_dessert_0.png" alt="" />
              <p>Sample 1</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_dessert_1.png" alt="" />
              <p>Sample 2</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_dessert_2.png" alt="" />
              <p>Sample 3</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_dessert_3.png" alt="" />
              <p>Sample 4</p>
            </div>
            <div class="image-card">
              <img src="media/inpainted_dessert_4.png" alt="" />
              <p>Sample 5</p>
            </div>
            <div class="image-card">
                <img src="media/fancy_dessert.jpg" alt="" />
                <p>Original</p>
            </div>
            <div class="image-card">
                <img src="media/desert_mask.jpg" alt="" />
                <p>Mask</p>
            </div>
          </section>
      </section>
      <section>
        <h2>Part 1.7.3 Text-Conditional Image-to-image Translation</h2>
        <p>
          We can add control to our previous results by changing th etext promp from "a high quality photo" to something more descriptive like "a rocket ship". The results below are for increasing values of i_start, as i_Start increases the model gets less "creative" and the output looks more like the input image.
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_1.png" alt="" />
            <p>Rocket ship at i_start=1</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_3.png" alt="" />
            <p>Rocket ship at i_start=3</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_5.png" alt="" />
            <p>Rocket ship at i_start=5</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_7.png" alt="" />
            <p>Rocket ship at i_start=7</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_10.png" alt="" />
            <p>Rocket ship at i_start=10</p>
          </div>
          <div class="image-card">
            <img src="media/cfg_generated_rocket_ship_20.png" alt="" />
            <p>Rocket ship at i_start=20</p>
          </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/cfg_generated_pencil_1.png" alt="" />
              <p>Pencil at i_start=1</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_generated_pencil_3.png" alt="" />
              <p>Pencil at i_start=3</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_generated_pencil_5.png" alt="" />
              <p>Pencil at i_start=5</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_generated_pencil_7.png" alt="" />
              <p>Pencil at i_start=7</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_generated_pencil_10.png" alt="" />
              <p>Pencil at i_start=10</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_generated_pencil_20.png" alt="" />
              <p>Pencil at i_start=20</p>
            </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/cfg_david_waterfall_1.png" alt="" />
              <p>Waterfall at i_start=1</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_david_waterfall_3.png" alt="" />
              <p>Waterfall at i_start=3</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_david_waterfall_5.png" alt="" />
              <p>Waterfall at i_start=5</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_david_waterfall_7.png" alt="" />
              <p>Waterfall at i_start=7</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_david_waterfall_10.png" alt="" />
              <p>Waterfall at i_start=10</p>
            </div>
            <div class="image-card">
              <img src="media/cfg_david_waterfall_20.png" alt="" />
              <p>Waterfall at i_start=20</p>
            </div>
          </section>
      </section>
      <section>
        <h2>Part 1.8 Visual Anagrams</h2>
        <p>
          Getting even more creative we can create an image that looks like one thing right side up and another thing upside down, similar to Salvador Dali's <em>Elephants Reflecting Swans</em>. The idea is to compute two noises, one for a given prompt for example "an oil painting of an old man" and another for the same image but flipped and with the prompt "an oil painting of people around a campfire". Then, average these two noises and use that as your noise. 
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/old_man_camp_fire (2).jpg" alt="" />
            <p>"Oil painting of an old man"</p>
          </div>
          <div class="image-card">
            <img src="media/man_dog.jpg" alt="" />
            <p>"A photo of a man""</p>
          </div>
          <div class="image-card">
            <img src="media/snowy_waterfall.jpg" alt="" />
            <p>"An oil painting of a snowy mountain village"</p>
          </div>
          <div class="image-card">
            <img src="media/amalfi_skull.jpg" alt="" />
            <p>"a photo of the amalfi cost"</p>
          </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/old_man_camp_fire (2).jpg" alt="" class="flipped-image" />
              <p>"An oil painting of people around a campfire"</p>
            </div>
            <div class="image-card">
              <img src="media/man_dog.jpg" alt="" class="flipped-image" />
              <p>"A photo of a dog"</p>
            </div>
            <div class="image-card">
              <img src="media/snowy_waterfall.jpg" alt="" class="flipped-image" />
              <p>"A lithograph of a waterfall"</p>
            </div>
            <div class="image-card">
              <img src="media/amalfi_skull.jpg" alt="" class="flipped-image" />
              <p>"A lithograph of a skull"</p>
            </div>
          </section>
      </section>
      <section>
        <h2>Part 1.9 Hybrid Images</h2>
        <p>
          Similar to project 2 where I took advantage of the way humans percieve high and low frequnecy visual data, we can use a diffusion model to mkae factorized images that look like one thing from a far and another from close up. The idea is similar to the previous par tbut instead of flipping the image we just run a high pass and low pass filter on the image and take the noise with respect to two different text prompts, then sum this noise to get our overall noise. The results from this part are not as pleasing as the Visual Anagrams, I palyed around with tryong to weight the noise differently with emphasis on the "harder" prompt but still many of my images look dissatisfying.
        </p>
        <section class="image-section">
          <div class="image-card">
            <img src="media/waterfall_skull_hybrid.jpg" alt="" />
            <p>"A lithograph of a skull" and "A lithograph of a waterfall"</p>
          </div>
          <div class="image-card">
            <img src="media/waterfall_snowy_hybrid.jpg" alt="" />
            <p>"An oil painting of a snowy mountain village" and "A lithograph of a waterfall"</p>
          </div>
          <div class="image-card">
            <img src="media/skull_amalfi_hybrid.jpg" alt="" />
            <p>"A lithograph of a skull" and "a photo of the amalfi cost"</p>
          </div>
          <div class="image-card">
            <img src="media/skull_amalfi_hybrid (1).jpg" alt="" />
            <p>"A lithograph of a skull" and "a photo of the amalfi cost" w/ emphasis on amalfi.</p>
          </div>
        </section>
      </section>
      <section>
        <h2>Conclusion</h2>
        <p>
          This project was quite challenging and involved lots of trial and error with different input images and prompts and playing around with how to use the noise appropriately. However, it was quite rewarding and provided great insight into the capabilities of diffusion models and how to get creative and create some fun images that mess with human perception.
        </p>
    </section>
    </div>
    <div class="container">
        <section>
            <h2>Diffusion Models from Scratch! (Part B)</h2>
            <p>
              In this next part of the project, I'll be training my own diffusion model on MNIST.
            </p>
        </section>
        <section>
            <h2>1.1 Implementing the UNet</h2>
            <p>
              The first step is to implement the denoiser as a <a href="https://arxiv.org/abs/1505.04597"> UNet.</a> A UNet has an encoder-decoder structure with skip connections which aims to capture the context of the input image by progressively reducing its spatial dimensions, and reconstructs the spatial information to its original resolution while maintaining the fine-grined details. My UNet follows the structure below.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/Unconditional_unet.png" alt="" />
            </div>
        </section>

        <section>
            <h2>1.2 Using the UNet to Train a Denoiser</h2>
            <p>
              To begin we'll just visualize varrying levels of noise on a few MNIST samples.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/mnist_noising_process.png" alt="" />
            </div>
        </section>

        <section>
            <h2>1.2.1 Training</h2>
            <p>
              Now it's time to train the model to denoise. I trained the denoiser on noisy images <em>z</em> with &sigma; = 0.5 applied to a clean image <em>x</em>. I used a batch size of 256 and 5 epochs with 128 hidden layers and the Adam optimizer with learning rate 1e-4.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/training_loss_plot.png" alt="" />
              <p>Training Loss Curve</p>
            </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/denoising_results_epoch1.png" alt="" />
              <p>Results on digits from the test set after 1 epoch</p>
            </div>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/denoising_results_epoch5.png" alt="" />
            <p>Results on digits from the test set after 5 epochs</p>
            </div>
        </section>

        <section>
            <h2>1.2.2 Out-of-Distribution Testing</h2>
            <p>
              The denoiser was trained on &sigma; = 0.5, but here I visualize how it performs on different sigma's.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/denoising_results_vary_noise.png" alt="" />
              <p>Results on digits from the test set with varrying noise levels.</p>
            </div>
        </section>
        <section>
            <h2>2.1 Adding Time Conditioning to UNet</h2>
            <p>
              To condition on time we need to inject a scalar <em>t</em> into the UNet like so.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/t_cond_graphic.png" alt="" />
            </div>
        </section>
        <section>
            <h2>2.2 Training the UNet</h2>
            <p>
             It's now time to train the UNet. This looks the same as before but this time we use our time conditioned model to predict the noise passing in a random <em>t</em>. This time training for 20 epochs because this task is more difficult and use 64 hidden channels. Below is the training loss curve.
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/training_loss_curve_t_cond_unet (1).png" alt="" />
            </div>
            <p>Training loss curve for time-conditioned UNet</p>
        </section>
        <section>
            <h2>2.3 Sampling from the UNet</h2>
            <p>
             For this part, we sample similar to how we did with the DeepFloyd model in part A; however, this time we don't need to predict the variance and can instead use 
             <p>
                A list <b>&Beta;</b> of length <b>T</b> such that:
            </p>
            <ul>
                <li>&Beta;<sub>0</sub> = 0.0001</li>
                <li>&Beta;<sub>T</sub> = 0.02</li>
                <li>All other elements &Beta;<sub>t</sub> for <i>t</i> &isin; {1, ..., T-1} are evenly spaced between the two.</li>
            </ul>
            The sampling results for the 5th and 20th epochs are below
            </p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/t_cond_samp_5_epochs.png" alt="" />
            </div>
            <p>Samples for time-conditioned UNet at epoch 5</p>
        </section>
        <section class="image-section">
            <div class="image-card">
              <img src="media/t_cond_samp_20_epochs.png" alt="" />
            </div>
            <p>Samples for time-conditioned UNet at epoch 20</p>
        </section>
    </div>
  </body>
</html>
